{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "8Tx4a625qBAN"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.datasets import fashion_mnist, cifar100\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "tLcoVZSq6yfJ"
   },
   "outputs": [],
   "source": [
    "# fashion_mnist dataset 로드\n",
    "(X_train,y_train),(X_test,y_test) = cifar100.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "knvCgFGRKMvv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfSoPgrWHET1"
   },
   "source": [
    "### 1. cifar100를 이용하여 VGG16 기반 CNN model을 학습하여 생성하시오. \n",
    "- VGG16은 ResNet50와 동일한 방식으로 사용함\n",
    "- epoch은 10 내외로 설정하되, 이 외의 파라미터는 자유롭게 선정하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4OxfPYiDKdB5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3500/3500 [==============================] - 575s 164ms/step - loss: 4.6092 - acc: 0.0099 - val_loss: 4.6068 - val_acc: 0.0081\n",
      "Epoch 2/10\n",
      " 483/3500 [===>..........................] - ETA: 7:36 - loss: 4.6054 - acc: 0.0104"
     ]
    }
   ],
   "source": [
    "# 코드 작성\n",
    "# 학습 시, 학습데이터의 30%를 검증(validation) 데이터로 이용하시오.\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "Xtrain = X_train/255\n",
    "Xtest = X_test/255\n",
    "\n",
    "CNN_model = Sequential([\n",
    "    VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(100, activation='softmax')\n",
    "])\n",
    "\n",
    "CNN_model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc'])\n",
    "\n",
    "ep = 10\n",
    "batch = 10\n",
    "val_ratio = 0.3\n",
    "\n",
    "CNN_result = CNN_model.fit(Xtrain, y_train,\n",
    "                           epochs=ep,\n",
    "                           batch_size=batch,\n",
    "                           validation_split=val_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. VGG16, ResNet50 등 미리 구현된 layer를 활용하는 transfer learning에 대해 간단히 설명하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "미리 학습된 신경망의 지식을 통해 새로운 작업을 진행하는 것으로 데이터 부족 문제에 대한 해결책으로 생각할 수 있습니다. 이를 통해 훈력 시간을 절약할 수 있으며, 기존 이미지의 일반적인 특징을 학습했기 때문에 성능 향상을 노려볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2k2eX9gNGc_"
   },
   "source": [
    "### 3. 생성된 model에 x_test 이미지를 적용했을 때의 정확도를 구하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HmYh5yc-NRun"
   },
   "outputs": [],
   "source": [
    "# 코드 작성\n",
    "# 정확도: ??\n",
    "\n",
    "print('정확도 : ', CNN_model.evaluate(Xtest,y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 학습 과정의 epoch에 대한 training data 및 validation 데이터의 loss와 accuracy 변화를 차트로 그리시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = CNN_result.history['loss']\n",
    "val_loss = CNN_result.history['val_loss']\n",
    "train_acc = CNN_result.history['acc']\n",
    "val_acc = CNN_result.history['val_acc']\n",
    "\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_loss, 'b-', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r-', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_acc, 'b-', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'r-', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPPP84XAaHxIXxvqeJqGuI5",
   "collapsed_sections": [],
   "name": "CNN_cifar100.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
